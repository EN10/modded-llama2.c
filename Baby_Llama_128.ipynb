{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/eniompw/modded-llama2.c/blob/main/Baby_Llama_128.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OnipH4BHgpu1",
    "outputId": "e19782c5-7814-456c-ce3d-6161b57ba60e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'modded-llama2.c'...\n",
      "remote: Enumerating objects: 21, done.\u001b[K\n",
      "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
      "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
      "remote: Total 21 (delta 4), reused 13 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (21/21), 41.98 KiB | 20.99 MiB/s, done.\n",
      "Resolving deltas: 100% (4/4), done.\n"
     ]
    }
   ],
   "source": [
    "# training and inference code\n",
    "!git clone https://github.com/eniompw/modded-llama2.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tx04_T-pv1zf",
    "outputId": "405b9e5a-d779-4697-edad-612d58af6a10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-26 21:19:04--  https://huggingface.co/datasets/enio/TinyStories/resolve/main/tok128/tok128.model\n",
      "Resolving huggingface.co (huggingface.co)... 13.33.45.68, 13.33.45.37, 13.33.45.10, ...\n",
      "Connecting to huggingface.co (huggingface.co)|13.33.45.68|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs-us-1.hf.co/repos/65/c8/65c8615bfd6b6d94c8e62381ee6653578b439f71ff04b86aaefa9828dec8bb70/e4794cc7590440c422b6d63123f6f10fbc7ec83f8fc281c60296cbef61f772ac?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tok128.model%3B+filename%3D%22tok128.model%22%3B&Expires=1743027545&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MzAyNzU0NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzY1L2M4LzY1Yzg2MTViZmQ2YjZkOTRjOGU2MjM4MWVlNjY1MzU3OGI0MzlmNzFmZjA0Yjg2YWFlZmE5ODI4ZGVjOGJiNzAvZTQ3OTRjYzc1OTA0NDBjNDIyYjZkNjMxMjNmNmYxMGZiYzdlYzgzZjhmYzI4MWM2MDI5NmNiZWY2MWY3NzJhYz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=U44elyy5RtHA0rYBCe4vfHxsZHmTyeNuZcp7FsVtatMCQzV1azP7H8HKLtXXyeXZBvmaEW1gCAyVuZJHVmAGuA02RNf0jLyDRrxFSTpWDDgx4dDnwjEE-ixikwYtecTSjQ6wNY4tjIJvtyYJ%7E6SMXHAkpwQNRwvdN4oJ9ECZYQKUOMq%7EfNYPZ4f53VLuRXxQ9YLXaG1CBsfklS1d2J7Sr7sNQHqAe80pJ56E3oOcP5uvmD-dtczmFFfWxbDlDKIGXw6L7KHWRX8uEvheemDjRYhAq6VZt1uYtJvjuJgPBjO7TVrJ%7EUpyhiIvsBOqqnqE3JTluplYCsaMsCXxZ3OcPA__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
      "--2025-03-26 21:19:05--  https://cdn-lfs-us-1.hf.co/repos/65/c8/65c8615bfd6b6d94c8e62381ee6653578b439f71ff04b86aaefa9828dec8bb70/e4794cc7590440c422b6d63123f6f10fbc7ec83f8fc281c60296cbef61f772ac?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tok128.model%3B+filename%3D%22tok128.model%22%3B&Expires=1743027545&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MzAyNzU0NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzY1L2M4LzY1Yzg2MTViZmQ2YjZkOTRjOGU2MjM4MWVlNjY1MzU3OGI0MzlmNzFmZjA0Yjg2YWFlZmE5ODI4ZGVjOGJiNzAvZTQ3OTRjYzc1OTA0NDBjNDIyYjZkNjMxMjNmNmYxMGZiYzdlYzgzZjhmYzI4MWM2MDI5NmNiZWY2MWY3NzJhYz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=U44elyy5RtHA0rYBCe4vfHxsZHmTyeNuZcp7FsVtatMCQzV1azP7H8HKLtXXyeXZBvmaEW1gCAyVuZJHVmAGuA02RNf0jLyDRrxFSTpWDDgx4dDnwjEE-ixikwYtecTSjQ6wNY4tjIJvtyYJ%7E6SMXHAkpwQNRwvdN4oJ9ECZYQKUOMq%7EfNYPZ4f53VLuRXxQ9YLXaG1CBsfklS1d2J7Sr7sNQHqAe80pJ56E3oOcP5uvmD-dtczmFFfWxbDlDKIGXw6L7KHWRX8uEvheemDjRYhAq6VZt1uYtJvjuJgPBjO7TVrJ%7EUpyhiIvsBOqqnqE3JTluplYCsaMsCXxZ3OcPA__&Key-Pair-Id=K24J24Z295AEI9\n",
      "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 3.165.102.87, 3.165.102.71, 3.165.102.81, ...\n",
      "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|3.165.102.87|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1474 (1.4K) [binary/octet-stream]\n",
      "Saving to: ‘tok128.model’\n",
      "\n",
      "tok128.model        100%[===================>]   1.44K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-03-26 21:19:05 (599 MB/s) - ‘tok128.model’ saved [1474/1474]\n",
      "\n",
      "--2025-03-26 21:19:05--  https://huggingface.co/datasets/enio/TinyStories/raw/main/tok128/tok128.vocab\n",
      "Resolving huggingface.co (huggingface.co)... 13.33.45.68, 13.33.45.10, 13.33.45.37, ...\n",
      "Connecting to huggingface.co (huggingface.co)|13.33.45.68|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 874 [text/plain]\n",
      "Saving to: ‘tok128.vocab’\n",
      "\n",
      "tok128.vocab        100%[===================>]     874  --.-KB/s    in 0s      \n",
      "\n",
      "2025-03-26 21:19:05 (383 MB/s) - ‘tok128.vocab’ saved [874/874]\n",
      "\n",
      "--2025-03-26 21:19:05--  https://huggingface.co/datasets/enio/TinyStories/resolve/main/tok128/tok128.tar.gz\n",
      "Resolving huggingface.co (huggingface.co)... 13.33.45.37, 13.33.45.84, 13.33.45.68, ...\n",
      "Connecting to huggingface.co (huggingface.co)|13.33.45.37|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs-us-1.hf.co/repos/65/c8/65c8615bfd6b6d94c8e62381ee6653578b439f71ff04b86aaefa9828dec8bb70/8c269e1c67aaef8c3addd0b229f4df8cdba103aaca25e7c0e6ce2f83610fc764?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tok128.tar.gz%3B+filename%3D%22tok128.tar.gz%22%3B&response-content-type=application%2Fgzip&Expires=1743027546&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MzAyNzU0Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzY1L2M4LzY1Yzg2MTViZmQ2YjZkOTRjOGU2MjM4MWVlNjY1MzU3OGI0MzlmNzFmZjA0Yjg2YWFlZmE5ODI4ZGVjOGJiNzAvOGMyNjllMWM2N2FhZWY4YzNhZGRkMGIyMjlmNGRmOGNkYmExMDNhYWNhMjVlN2MwZTZjZTJmODM2MTBmYzc2ND9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=ABPoYpeu5lkyQDxS7k21y-TFDxgnX-3dKnJeX2i1vvT1tFWBgmbuwUa6ReeWjB71VELNmAKo15MyKqzawj9EF75ICj59NYIROsba5TelXe3bbjcCrxJjeVNo%7EiPkafnAY3qALcs%7Exxyv9pDq0ZAASxrCp7EydbZs6R2xt9RCOR7SUSfMmLEdcJJEwTss3nzstK52KhkgoAdLWUg7zsyYz2c7fDFq2ph-oxAueYN30skQW3hPpT91AkJIzq5ozrgXAbIIlxqFY-Ee8SZvU3tI4CQq5xMhnPyeyXGfTcfOdczjIdycE7Xh0MR3GABH-d6Y2-xjI4-5qEzMwksJ55r5BQ__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
      "--2025-03-26 21:19:06--  https://cdn-lfs-us-1.hf.co/repos/65/c8/65c8615bfd6b6d94c8e62381ee6653578b439f71ff04b86aaefa9828dec8bb70/8c269e1c67aaef8c3addd0b229f4df8cdba103aaca25e7c0e6ce2f83610fc764?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tok128.tar.gz%3B+filename%3D%22tok128.tar.gz%22%3B&response-content-type=application%2Fgzip&Expires=1743027546&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MzAyNzU0Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzY1L2M4LzY1Yzg2MTViZmQ2YjZkOTRjOGU2MjM4MWVlNjY1MzU3OGI0MzlmNzFmZjA0Yjg2YWFlZmE5ODI4ZGVjOGJiNzAvOGMyNjllMWM2N2FhZWY4YzNhZGRkMGIyMjlmNGRmOGNkYmExMDNhYWNhMjVlN2MwZTZjZTJmODM2MTBmYzc2ND9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=ABPoYpeu5lkyQDxS7k21y-TFDxgnX-3dKnJeX2i1vvT1tFWBgmbuwUa6ReeWjB71VELNmAKo15MyKqzawj9EF75ICj59NYIROsba5TelXe3bbjcCrxJjeVNo%7EiPkafnAY3qALcs%7Exxyv9pDq0ZAASxrCp7EydbZs6R2xt9RCOR7SUSfMmLEdcJJEwTss3nzstK52KhkgoAdLWUg7zsyYz2c7fDFq2ph-oxAueYN30skQW3hPpT91AkJIzq5ozrgXAbIIlxqFY-Ee8SZvU3tI4CQq5xMhnPyeyXGfTcfOdczjIdycE7Xh0MR3GABH-d6Y2-xjI4-5qEzMwksJ55r5BQ__&Key-Pair-Id=K24J24Z295AEI9\n",
      "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 3.165.102.87, 3.165.102.71, 3.165.102.81, ...\n",
      "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|3.165.102.87|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1288810573 (1.2G) [application/gzip]\n",
      "Saving to: ‘tok128.tar.gz’\n",
      "\n",
      "tok128.tar.gz       100%[===================>]   1.20G  22.2MB/s    in 55s     \n",
      "\n",
      "2025-03-26 21:20:01 (22.3 MB/s) - ‘tok128.tar.gz’ saved [1288810573/1288810573]\n",
      "\n",
      "/bin/bash: line 1: cd: llama2.c: No such file or directory\n",
      "/bin/bash: line 1: cd: llama2.c: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ./modded-llama2.c/data\n",
    "# Download files in parallel directly into the target directory\n",
    "!wget -P ./modded-llama2.c/data https://huggingface.co/datasets/enio/TinyStories/resolve/main/tok128/tok128.model & \\\n",
    "  wget -P ./modded-llama2.c/data https://huggingface.co/datasets/enio/TinyStories/raw/main/tok128/tok128.vocab & \\\n",
    "  wget -P ./modded-llama2.c/data https://huggingface.co/datasets/enio/TinyStories/resolve/main/tok128/tok128.tar.gz & \\\n",
    "  wait\n",
    "\n",
    "# Untar the large file after all downloads are complete\n",
    "!tar -I pigz -xf ./modded-llama2.c/data/tok128.tar.gz -C ./modded-llama2.c/data/\n",
    "\n",
    "# compile run / inference executable\n",
    "!cd modded-llama2.c && gcc -O3 -o run run.c -lm\n",
    "# create tok105.bin\n",
    "!cd modded-llama2.c && python tokenizer.py --tokenizer-model=data/tok128.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sdMK1MW8g4eM",
    "outputId": "8a944ff2-780d-4601-ee2e-4a9e7ed86770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: vocab_source = custom\n",
      "Overriding: vocab_size = 128\n",
      "Overriding: compile = False\n",
      "Overriding: dim = 128\n",
      "Overriding: n_layers = 5\n",
      "Overriding: n_heads = 8\n",
      "Overriding: n_kv_heads = 4\n",
      "Overriding: batch_size = 32\n",
      "Overriding: always_save_checkpoint = True\n",
      "Overriding: eval_interval = 100\n",
      "Overriding: max_iters = 100\n",
      "Original vocab size: 128, Padded vocab size: 128\n",
      "tokens per iteration will be: 65,536\n",
      "breaks down as: 4 grad accum steps * 1 processes * 32 batch size * 512 max seq len\n",
      "Initializing a new model from scratch\n",
      "/content/modded-llama2.c/train.py:195: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == \"float16\"))\n",
      "num decayed parameter tensors: 36, with 937,984 parameters\n",
      "num non-decayed parameter tensors: 11, with 1,408 parameters\n",
      "using fused AdamW: True\n",
      "Created a PretokDataset with rng seed 42\n",
      "Created a PretokDataset with rng seed 42\n",
      "Created a PretokDataset with rng seed 42\n",
      "step 0: train loss 4.8935, val loss 4.8944\n",
      "0 | loss 4.8968 | lr 5.000000e-04 | 2701.54ms\n",
      "10 | loss 4.0508 | lr 5.000000e-04 | 213.05ms\n",
      "20 | loss 3.6289 | lr 5.000000e-04 | 212.27ms\n",
      "30 | loss 3.3707 | lr 5.000000e-04 | 211.99ms\n",
      "40 | loss 3.2017 | lr 5.000000e-04 | 212.14ms\n",
      "50 | loss 3.0660 | lr 5.000000e-04 | 212.76ms\n",
      "60 | loss 2.9744 | lr 5.000000e-04 | 212.95ms\n",
      "70 | loss 2.8724 | lr 5.000000e-04 | 213.78ms\n",
      "80 | loss 2.7699 | lr 5.000000e-04 | 213.11ms\n",
      "90 | loss 2.6620 | lr 5.000000e-04 | 213.84ms\n",
      "Created a PretokDataset with rng seed 42\n",
      "Created a PretokDataset with rng seed 42\n",
      "step 100: train loss 2.5989, val loss 2.5960\n",
      "saving checkpoint to out\n",
      "wrote out/model.bin\n",
      "100 | loss 2.5778 | lr 5.000000e-05 | 2216.69ms\n"
     ]
    }
   ],
   "source": [
    "# train neural net\n",
    "!cd modded-llama2.c && python train.py --vocab_source=custom --vocab_size=128 --compile=False \\\n",
    "  --dim=128 --n_layers=5 --n_heads=8 --n_kv_heads=4 --batch_size=32 \\\n",
    "  --always_save_checkpoint=True --eval_interval=100 --max_iters=100 #--init_from='resume'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1-ylANKlOfCr",
    "outputId": "dd67be79-1816-447d-c59a-ede14585f967"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time on a thave ot cape, bunt pily. She dime wel nomiker withat to said or held and gamm bolk. Maned soth nare solf day, \" Amom gilys nont, buse funt. Ther all onend hay. <unk>\"<unk>I wer cor.<unk>Limet bens a hay cimy. Mamde groked Lid toy and hirs ove shap ugirongen. Onew her ot bily po nene said.<unk>They w\n",
      "achieved tok/s: 885.416667\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "!cd ./modded-llama2.c && ./run out/model.bin -z data/tok128.bin -t 0.8 -n 256 -i \"Once upon a time \""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
