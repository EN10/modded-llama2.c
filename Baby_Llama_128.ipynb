{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EN10/modded-llama2.c/blob/main/Baby_Llama_128.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnipH4BHgpu1",
        "outputId": "2416a9e5-e07b-492b-d437-bea19909ba52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'modded-llama2.c'...\n",
            "remote: Enumerating objects: 32, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 32 (delta 10), reused 11 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (32/32), 56.99 KiB | 5.18 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n"
          ]
        }
      ],
      "source": [
        "# training and inference code\n",
        "!git clone https://github.com/eniompw/modded-llama2.c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "Tx04_T-pv1zf",
        "outputId": "881fe813-9a0c-4efa-f7c7-4fc733934e34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-29 09:40:44--  https://huggingface.co/datasets/enio/TinyStories/resolve/main/tok128/tok128.tar.gz\n",
            "--2025-05-29 09:40:44--  https://huggingface.co/datasets/enio/TinyStories/raw/main/tok128/tok128.vocab\n",
            "Resolving huggingface.co (huggingface.co)... Resolving huggingface.co (huggingface.co)... --2025-05-29 09:40:44--  https://huggingface.co/datasets/enio/TinyStories/resolve/main/tok128/tok128.model\n",
            "Resolving huggingface.co (huggingface.co)... 3.163.189.114, 3.163.189.37, 3.163.189.90, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.163.189.114|:443... 3.163.189.90, 3.163.189.37, 3.163.189.74, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.163.189.90|:443... connected.\n",
            "connected.\n",
            "3.163.189.90, 3.163.189.74, 3.163.189.114, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.163.189.90|:443... HTTP request sent, awaiting response... connected.\n",
            "HTTP request sent, awaiting response... HTTP request sent, awaiting response... 200 OK\n",
            "Length: 874 [text/plain]\n",
            "Saving to: ‘./modded-llama2.c/data/tok128.vocab’\n",
            "\n",
            "\rtok128.vocab          0%[                    ]       0  --.-KB/s               \rtok128.vocab        100%[===================>]     874  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-29 09:40:44 (430 MB/s) - ‘./modded-llama2.c/data/tok128.vocab’ saved [874/874]\n",
            "\n",
            "302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/65/c8/65c8615bfd6b6d94c8e62381ee6653578b439f71ff04b86aaefa9828dec8bb70/e4794cc7590440c422b6d63123f6f10fbc7ec83f8fc281c60296cbef61f772ac?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tok128.model%3B+filename%3D%22tok128.model%22%3B&Expires=1748515244&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0ODUxNTI0NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzY1L2M4LzY1Yzg2MTViZmQ2YjZkOTRjOGU2MjM4MWVlNjY1MzU3OGI0MzlmNzFmZjA0Yjg2YWFlZmE5ODI4ZGVjOGJiNzAvZTQ3OTRjYzc1OTA0NDBjNDIyYjZkNjMxMjNmNmYxMGZiYzdlYzgzZjhmYzI4MWM2MDI5NmNiZWY2MWY3NzJhYz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=RrRhqrjY0onhyf0TIBQUSM6VR-h2UlsuvSPdGhI9iwSQaMd5m6DrBpMjy3FuLEoV6qQzrzOw6KMMjAPkmdh03N2Uxld9%7EbRMKPPL%7EIwhVdeqeNNNtOTauwSva8sM2AzAFuSJLgV4MhRnthTodglZS3MvPABEps5EDy9F%7EKi22efyaKVnYQjbDKIzBTztt0bAmmDyHGcerfnMVy8zIala-b9WDfN7GEs0yqDUz5uF2aK925Yl31Fots7cMRcivCijcTl0XTThsiu6dr715UVG7bF2Z5LQFKAcaqCuC303nP-Vkw956zoL-cg9EXbOiLbfisEwdIPnlM2xCUDS0TurlA__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-05-29 09:40:44--  https://cdn-lfs-us-1.hf.co/repos/65/c8/65c8615bfd6b6d94c8e62381ee6653578b439f71ff04b86aaefa9828dec8bb70/e4794cc7590440c422b6d63123f6f10fbc7ec83f8fc281c60296cbef61f772ac?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tok128.model%3B+filename%3D%22tok128.model%22%3B&Expires=1748515244&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0ODUxNTI0NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzY1L2M4LzY1Yzg2MTViZmQ2YjZkOTRjOGU2MjM4MWVlNjY1MzU3OGI0MzlmNzFmZjA0Yjg2YWFlZmE5ODI4ZGVjOGJiNzAvZTQ3OTRjYzc1OTA0NDBjNDIyYjZkNjMxMjNmNmYxMGZiYzdlYzgzZjhmYzI4MWM2MDI5NmNiZWY2MWY3NzJhYz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=RrRhqrjY0onhyf0TIBQUSM6VR-h2UlsuvSPdGhI9iwSQaMd5m6DrBpMjy3FuLEoV6qQzrzOw6KMMjAPkmdh03N2Uxld9%7EbRMKPPL%7EIwhVdeqeNNNtOTauwSva8sM2AzAFuSJLgV4MhRnthTodglZS3MvPABEps5EDy9F%7EKi22efyaKVnYQjbDKIzBTztt0bAmmDyHGcerfnMVy8zIala-b9WDfN7GEs0yqDUz5uF2aK925Yl31Fots7cMRcivCijcTl0XTThsiu6dr715UVG7bF2Z5LQFKAcaqCuC303nP-Vkw956zoL-cg9EXbOiLbfisEwdIPnlM2xCUDS0TurlA__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/65/c8/65c8615bfd6b6d94c8e62381ee6653578b439f71ff04b86aaefa9828dec8bb70/8c269e1c67aaef8c3addd0b229f4df8cdba103aaca25e7c0e6ce2f83610fc764?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tok128.tar.gz%3B+filename%3D%22tok128.tar.gz%22%3B&response-content-type=application%2Fgzip&Expires=1748515244&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0ODUxNTI0NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzY1L2M4LzY1Yzg2MTViZmQ2YjZkOTRjOGU2MjM4MWVlNjY1MzU3OGI0MzlmNzFmZjA0Yjg2YWFlZmE5ODI4ZGVjOGJiNzAvOGMyNjllMWM2N2FhZWY4YzNhZGRkMGIyMjlmNGRmOGNkYmExMDNhYWNhMjVlN2MwZTZjZTJmODM2MTBmYzc2ND9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=LrDedef-NHq02SBNcClsETxGeHx3bqcrB5dv2uQIPkHbbqjIak8h6TGoJYBTRIiei3DPxr8cw6aKBwaM4-LRrHTclJsbkYxbXCTDVrl7RuaAcEKxFxlUKQj9vh9HhPuxebGxo2fB8j0bJRriSFFJNP2H85nMGyQ5q8B3clSrV18yyuWJt98fj4BPSIG%7EBYF-ouoLqV73fvFbfmeIiwkdk4nN8MOkRZQ81tEgl1dtzTnYDS4k28GZdBBebfsW3mFQuWndXR%7EUP9k6iL4Q2BCEShqLP-FbIsCey7DA3ZqgV5VabuYCHPbxg0o29jEEzuSsCCDrOjipVRE1-ae5l%7ENW%7EA__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-05-29 09:40:45--  https://cdn-lfs-us-1.hf.co/repos/65/c8/65c8615bfd6b6d94c8e62381ee6653578b439f71ff04b86aaefa9828dec8bb70/8c269e1c67aaef8c3addd0b229f4df8cdba103aaca25e7c0e6ce2f83610fc764?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tok128.tar.gz%3B+filename%3D%22tok128.tar.gz%22%3B&response-content-type=application%2Fgzip&Expires=1748515244&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0ODUxNTI0NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzY1L2M4LzY1Yzg2MTViZmQ2YjZkOTRjOGU2MjM4MWVlNjY1MzU3OGI0MzlmNzFmZjA0Yjg2YWFlZmE5ODI4ZGVjOGJiNzAvOGMyNjllMWM2N2FhZWY4YzNhZGRkMGIyMjlmNGRmOGNkYmExMDNhYWNhMjVlN2MwZTZjZTJmODM2MTBmYzc2ND9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=LrDedef-NHq02SBNcClsETxGeHx3bqcrB5dv2uQIPkHbbqjIak8h6TGoJYBTRIiei3DPxr8cw6aKBwaM4-LRrHTclJsbkYxbXCTDVrl7RuaAcEKxFxlUKQj9vh9HhPuxebGxo2fB8j0bJRriSFFJNP2H85nMGyQ5q8B3clSrV18yyuWJt98fj4BPSIG%7EBYF-ouoLqV73fvFbfmeIiwkdk4nN8MOkRZQ81tEgl1dtzTnYDS4k28GZdBBebfsW3mFQuWndXR%7EUP9k6iL4Q2BCEShqLP-FbIsCey7DA3ZqgV5VabuYCHPbxg0o29jEEzuSsCCDrOjipVRE1-ae5l%7ENW%7EA__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 13.224.14.81, 13.224.14.28, 13.224.14.54, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|13.224.14.81|:443... 108.138.94.16, 108.138.94.114, 108.138.94.37, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|108.138.94.16|:443... connected.\n",
            "connected.\n",
            "HTTP request sent, awaiting response... HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1474 (1.4K) [binary/octet-stream]\n",
            "Saving to: ‘./modded-llama2.c/data/tok128.model’\n",
            "\n",
            "tok128.model        100%[===================>]   1.44K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-29 09:40:45 (581 MB/s) - ‘./modded-llama2.c/data/tok128.model’ saved [1474/1474]\n",
            "\n",
            "200 OK\n",
            "Length: 1288810573 (1.2G) [application/gzip]\n",
            "Saving to: ‘./modded-llama2.c/data/tok128.tar.gz’\n",
            "\n",
            "tok128.tar.gz       100%[===================>]   1.20G   181MB/s    in 6.4s    \n",
            "\n",
            "2025-05-29 09:40:51 (192 MB/s) - ‘./modded-llama2.c/data/tok128.tar.gz’ saved [1288810573/1288810573]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ./modded-llama2.c/data\n",
        "# Download files in parallel directly into the target directory\n",
        "!wget -P ./modded-llama2.c/data https://huggingface.co/datasets/enio/TinyStories/resolve/main/tok128/tok128.model & \\\n",
        "  wget -P ./modded-llama2.c/data https://huggingface.co/datasets/enio/TinyStories/raw/main/tok128/tok128.vocab & \\\n",
        "  wget -P ./modded-llama2.c/data https://huggingface.co/datasets/enio/TinyStories/resolve/main/tok128/tok128.tar.gz & \\\n",
        "  wait\n",
        "\n",
        "# Untar the large file after all downloads are complete\n",
        "!tar -I pigz -xf ./modded-llama2.c/data/tok128.tar.gz -C ./modded-llama2.c/data/\n",
        "\n",
        "# compile run / inference executable\n",
        "!cd modded-llama2.c && gcc -O3 -o run run.c -lm\n",
        "# create tok105.bin\n",
        "!cd modded-llama2.c && python tokenizer.py --tokenizer-model=data/tok128.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "sdMK1MW8g4eM",
        "outputId": "29f68241-7249-4201-b8ed-89989e59023b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding: vocab_source = custom\n",
            "Overriding: vocab_size = 128\n",
            "Overriding: compile = False\n",
            "Overriding: dim = 128\n",
            "Overriding: n_layers = 5\n",
            "Overriding: n_heads = 8\n",
            "Overriding: n_kv_heads = 4\n",
            "Overriding: batch_size = 32\n",
            "Overriding: always_save_checkpoint = True\n",
            "Overriding: eval_interval = 100\n",
            "Overriding: max_iters = 100\n",
            "Starting run in out\n",
            "Vocab size (original/padded): 128/128\n",
            "Tokens per iteration: 65,536\n",
            "Max iterations: 100\n",
            "Compiling: False\n",
            "Initializing a new model from scratch\n",
            "Optimizer groups:\n",
            "  Group 0: 16,384 params, LR_mult=1.00, WD=0.0\n",
            "  Group 1: 1,408 params, LR_mult=0.10, WD=0.0\n",
            "  Group 2: 921,600 params, LR_mult=1.00, WD=0.1\n",
            "Total optimizable parameters: 939,392\n",
            "Using fused AdamW: True\n",
            "Created a PretokDataset with rng seed 42\n",
            "Starting training loop...\n",
            "Created a PretokDataset with rng seed 42\n",
            "Created a PretokDataset with rng seed 42\n",
            "step 0: train loss 4.9223, val loss 4.9226\n",
            "New best val loss: 4.9226\n",
            "Saving checkpoint to out/ckpt.pt\n",
            "wrote out/model.bin\n",
            "0 | loss 4.9256 | lr 5.00e-04 | 3600.07ms\n",
            "10 | loss 4.0614 | lr 5.00e-04 | 212.30ms\n",
            "20 | loss 3.6292 | lr 5.00e-04 | 213.59ms\n",
            "30 | loss 3.3815 | lr 5.00e-04 | 212.38ms\n",
            "40 | loss 3.2216 | lr 5.00e-04 | 212.50ms\n",
            "50 | loss 3.0882 | lr 5.00e-04 | 212.53ms\n",
            "60 | loss 2.9923 | lr 5.00e-04 | 211.53ms\n",
            "70 | loss 2.8756 | lr 5.00e-04 | 213.13ms\n",
            "80 | loss 2.7735 | lr 5.00e-04 | 213.37ms\n",
            "90 | loss 2.6467 | lr 5.00e-04 | 213.34ms\n",
            "Created a PretokDataset with rng seed 42\n",
            "Created a PretokDataset with rng seed 42\n",
            "step 100: train loss 2.5751, val loss 2.5717\n",
            "New best val loss: 2.5717\n",
            "Saving checkpoint to out/ckpt.pt\n",
            "wrote out/model.bin\n",
            "Training finished.\n",
            "Best validation loss achieved: 2.5717\n"
          ]
        }
      ],
      "source": [
        "# train neural net\n",
        "!cd modded-llama2.c && python train.py --vocab_source=custom --vocab_size=128 --compile=False \\\n",
        "  --dim=128 --n_layers=5 --n_heads=8 --n_kv_heads=4 --batch_size=32 \\\n",
        "  --always_save_checkpoint=True --eval_interval=100 --max_iters=100 #--init_from='resume'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "1-ylANKlOfCr",
        "outputId": "d177c91d-9ff2-4253-fee5-056808bebd9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time pap and stappy bid a log.\"<unk>Tied to o wels a dererd thacked it. The made eadny. Saponed. Tis nos nory crols and days. Mis it ot cat ne save. Thoom mamed to gor the barle tige, \"<unk>\" Lit and ness as hady. Sue clen's none the tie, uts and thark to she tise, nory, Sile and saik. Mold saw a loat gallld a loplr d\n",
            "achieved tok/s: 913.978495\n"
          ]
        }
      ],
      "source": [
        "# inference\n",
        "!cd ./modded-llama2.c && ./run out/model.bin -z data/tok128.bin -t 0.8 -n 256 -i \"Once upon a time \""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}